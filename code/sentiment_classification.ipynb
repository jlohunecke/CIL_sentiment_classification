{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T20:36:05.379393Z",
     "start_time": "2024-05-02T20:36:04.367684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jacobleooskar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jacobleooskar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jacobleooskar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/Users/jacobleooskar/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_data\n",
    "from preprocess import preprocess\n",
    "from embed import Embedder\n",
    "from baselines import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_path_neg = \"../twitter-datasets/train_neg.txt\"\n",
    "train_path_pos = \"../twitter-datasets/train_pos.txt\"\n",
    "test_path = \"../twitter-datasets/test_data.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T20:36:05.379570Z",
     "start_time": "2024-05-02T20:36:05.376155Z"
    }
   },
   "id": "9547a8ae1d7dd5c1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test = load_data(train_path_neg, train_path_pos, test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T20:36:05.705252Z",
     "start_time": "2024-05-02T20:36:05.378712Z"
    }
   },
   "id": "5e1f756a76eceed3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train_tokens, X_val_tokens, X_test_tokens = preprocess(X_train, X_val, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T20:36:11.000593Z",
     "start_time": "2024-05-02T20:36:05.801157Z"
    }
   },
   "id": "c1b94db0c1251dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m embedder \u001B[38;5;241m=\u001B[39m Embedder()\n\u001B[1;32m      2\u001B[0m embedder_model \u001B[38;5;241m=\u001B[39m embedder\u001B[38;5;241m.\u001B[39mfit(X_train_tokens)\n\u001B[0;32m----> 3\u001B[0m X_train_tokens \u001B[38;5;241m=\u001B[39m \u001B[43membedder_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m X_val_tokens \u001B[38;5;241m=\u001B[39m embedder_model\u001B[38;5;241m.\u001B[39mtransform(X_val_tokens)\n\u001B[1;32m      5\u001B[0m X_test_tokens \u001B[38;5;241m=\u001B[39m embedder_model\u001B[38;5;241m.\u001B[39mtransform(X_test_tokens)\n",
      "File \u001B[0;32m~/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/sklearn/pipeline.py:905\u001B[0m, in \u001B[0;36mPipeline.transform\u001B[0;34m(self, X, **params)\u001B[0m\n\u001B[1;32m    903\u001B[0m Xt \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    904\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter():\n\u001B[0;32m--> 905\u001B[0m     Xt \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Xt\n",
      "File \u001B[0;32m~/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1434\u001B[0m, in \u001B[0;36mCountVectorizer.transform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   1431\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_vocabulary()\n\u001B[1;32m   1433\u001B[0m \u001B[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001B[39;00m\n\u001B[0;32m-> 1434\u001B[0m _, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfixed_vocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[1;32m   1436\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1276\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m raw_documents:\n\u001B[1;32m   1275\u001B[0m     feature_counter \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1276\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m \u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1277\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1278\u001B[0m             feature_idx \u001B[38;5;241m=\u001B[39m vocabulary[feature]\n",
      "File \u001B[0;32m~/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:110\u001B[0m, in \u001B[0;36m_analyze\u001B[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m preprocessor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 110\u001B[0m         doc \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m         doc \u001B[38;5;241m=\u001B[39m tokenizer(doc)\n",
      "File \u001B[0;32m~/Documents/Education/ETHZ/Curriculum/Semester02/02CILab/Project/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:68\u001B[0m, in \u001B[0;36m_preprocess\u001B[0;34m(doc, accent_function, lower)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03mapply to a document.\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    preprocessed string\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lower:\n\u001B[0;32m---> 68\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m()\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m accent_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m     doc \u001B[38;5;241m=\u001B[39m accent_function(doc)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()\n",
    "embedder_model = embedder.fit(X_train_tokens)\n",
    "X_train_tokens = embedder_model.transform(X_train_tokens)\n",
    "X_val_tokens = embedder_model.transform(X_val_tokens)\n",
    "X_test_tokens = embedder_model.transform(X_test_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T20:36:11.381265Z",
     "start_time": "2024-05-02T20:36:11.042753Z"
    }
   },
   "id": "3bf5800b7180fc98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "baseline_model = NaiveBayes()\n",
    "baseline_model.fit(X_train_tokens, y_train)\n",
    "baseline_model.evaluate(X_val_tokens, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T20:36:11.380381Z"
    }
   },
   "id": "8643eac426bd260b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "20f9d2b494037975"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
